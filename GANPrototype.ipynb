{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6Jxgv4uFL7axaKnW/IeUs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheBigAC/ImgToImgGAN/blob/main/GANPrototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySGIFpMkZscf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Import all modules\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from PIL import Image\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, ConvLSTM2D, Conv2D, Input\n",
        "from keras.layers import Activation, MaxPooling2D, UpSampling2D, Dropout, Flatten, Reshape\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from keras.preprocessing.image import load_img, array_to_img\n",
        "from keras.callbacks import Callback\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load and Preprocess Data\n",
        "drive.mount('/content/gdrive')\n",
        "path = \"/content/gdrive/MyDrive/AdvayChandra/MainModel/Data/\"\n",
        "directory = \"CMPFacades/\" # @param {type:\"string\"}\n",
        "train_file_name = \"traindata.pkl\" # @param {type:\"string\"}\n",
        "test_file_name = \"testdata.pkl\" # @param {type:\"string\"}\n",
        "\n",
        "with open(path + directory + train_file_name, 'rb') as file:\n",
        "  train = pickle.load(file)\n",
        "  y_train = tf.data.Dataset.from_tensor_slices(train[\"X_train\"]).batch(16)\n",
        "  X_train = tf.data.Dataset.from_tensor_slices(train[\"y_train\"]).batch(16)\n",
        "file.close()\n",
        "\n",
        "with open(path + directory + test_file_name, 'rb') as file:\n",
        "  test = pickle.load(file)\n",
        "  y_test = tf.data.Dataset.from_tensor_slices(test[\"X_test\"]).batch(16)\n",
        "  X_test = tf.data.Dataset.from_tensor_slices(test[\"y_test\"]).batch(16)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "NUH6bMbPJfuq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc32cef5-ce2f-4ddd-d4d1-e735efce2b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create the Generator\n",
        "\n",
        "def build_generator():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=64, strides=2, kernel_size=(4, 4), padding='valid', activation='mish', input_shape=(256, 256, 3)))\n",
        "  model.add(Conv2D(filters=64, strides=2, kernel_size=(4, 4), padding='valid', activation='mish'))\n",
        "  model.add(Conv2D(filters=64, strides=2, kernel_size=(4, 4), padding='valid', activation='mish'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(1350, activation='mish'))\n",
        "  model.add(Dense(675, activation='mish'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(768, activation='mish'))\n",
        "  model.add(Dense(768, activation='mish'))\n",
        "  model.add(Dense(768, activation='mish'))\n",
        "  model.add(Dense(256 * 256 * 3, activation='sigmoid'))\n",
        "  model.add(Reshape((256, 256, 3)))\n",
        "  return model\n",
        "\"\"\"\n",
        "def other_generator():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=64, strides=2, kernel_size=(4, 4), padding='same', activation='leaky_relu', input_shape=(256, 256, 3)))\n",
        "  model.add(Conv2D(filters=64, strides=2, kernel_size=(4, 4), padding='same', activation='leaky_relu', input_shape=(256, 256, 3)))\n",
        "  return model\n",
        "\"\"\"\n",
        "generator = build_generator()\n",
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqa9izx9ay4d",
        "outputId": "bb8ef68a-3ee3-4bd6-91f1-80eed5fe86aa",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 127, 127, 64)      3136      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 62, 62, 64)        65600     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 30, 30, 64)        65600     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 57600)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 57600)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1350)              77761350  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 675)               911925    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 675)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 768)               519168    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 768)               590592    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 768)               590592    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 196608)            151191552 \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 231699515 (883.86 MB)\n",
            "Trainable params: 231699515 (883.86 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create the Discriminator\n",
        "\n",
        "def build_discriminator():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=32, strides=2, kernel_size=(6, 6), padding='valid', activation='mish', input_shape=(256, 256, 3)))\n",
        "  model.add(Conv2D(filters=32, strides=2, kernel_size=(3, 3), padding='valid', activation='mish', input_shape=(256, 256, 3)))\n",
        "  model.add(Conv2D(filters=32, strides=2, kernel_size=(6, 6), padding='valid', activation='mish', input_shape=(256, 256, 3)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(841, activation='mish'))\n",
        "  model.add(Dense(116, activation='mish'))\n",
        "  model.add(Dense(116, activation='mish'))\n",
        "  model.add(Dense(58, activation='mish'))\n",
        "  model.add(Dense(29, activation='mish'))\n",
        "  model.add(Dense(29, activation='mish'))\n",
        "  model.add(Dense(14, activation='mish'))\n",
        "  model.add(Dense(14, activation='mish'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "DGHun9izy-H1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "e00a106a-9948-4212-8f20-c83ac5585f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 126, 126, 32)      3488      \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 62, 62, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 29, 29, 32)        36896     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 26912)             0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 26912)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 841)               22633833  \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 116)               97672     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 116)               13572     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 58)                6786      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 29)                1711      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 29)                870       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 14)                420       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 14)                210       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 15        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22804721 (86.99 MB)\n",
            "Trainable params: 22804721 (86.99 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create GAN Class\n",
        "\n",
        "class GAN(Model):\n",
        "  def __init__(self, generator, discriminator, *args, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.generator = generator\n",
        "    self.discriminator = discriminator\n",
        "  def compile(self, *args, **kwargs):\n",
        "    super().compile(*args, **kwargs)\n",
        "    self.g_opt = Adam(learning_rate=0.0001)\n",
        "    self.d_opt = Adam(learning_rate=0.00001)\n",
        "  def train_step(self, x_batch_train, y_batch_train):\n",
        "    real_images = y_batch_train\n",
        "    fake_images = self.generator(x_batch_train, training=False)\n",
        "\n",
        "    with tf.GradientTape() as d_tape:\n",
        "      yhat_real = self.discriminator(real_images, training=True)\n",
        "      yhat_fake = self.discriminator(fake_images, training=True)\n",
        "      yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
        "\n",
        "      y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
        "\n",
        "      noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n",
        "      noise_fake = 0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
        "      y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n",
        "\n",
        "      total_d_loss = BinaryCrossentropy(y_realfake, yhat_realfake)\n",
        "\n",
        "    dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables)\n",
        "    self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
        "\n",
        "    with tf.GradientTape() as g_tape:\n",
        "      gen_images = self.generator(X_batch_train, training=True)\n",
        "      predicted_labels = self.discriminator(gen_images, training=False)\n",
        "      total_g_loss = BinaryCrossentropy(tf.zeros_like(predicted_images), predicted_images)\n",
        "\n",
        "    ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
        "    self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
        "\n",
        "    return {\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}"
      ],
      "metadata": {
        "id": "Vs2_Ig8aF-ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create instance of GAN\n",
        "testGAN = GAN(generator, discriminator)\n",
        "testGAN.compile()"
      ],
      "metadata": {
        "id": "ewAX9KD6xM6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Callback Class\n",
        "class ModelMonitor(Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=128):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      for i in range(self.num_img):\n",
        "        input_image = random.choice(test[\"y_test\"])\n",
        "        generated_image = self.model.generator(input_image)\n",
        "        generated_image *= 255\n",
        "        generated_image.numpy()\n",
        "        final_image = np.concatenate((input_image, generated_image), axis = 1)\n",
        "        img = array_to_img(final_image)\n",
        "        img.save(os.path.join('Images', f'generated_img_{epoch}_{i}.png'))"
      ],
      "metadata": {
        "id": "DJQfQfI1x2JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = testGAN.fit(X_train, y_train, epochs=5, callbacks=[ModelMonitor()])"
      ],
      "metadata": {
        "id": "4PS7_3R-TrDZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "9d408344-65da-490d-8b6c-10714641cae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "`y` argument is not supported when using dataset as input.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f8d07439defe>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModelMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m_validate_args\u001b[0;34m(self, y, sample_weights, steps, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;31m# Arguments that shouldn't be passed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;34m\"`y` argument is not supported when using dataset as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: `y` argument is not supported when using dataset as input."
          ]
        }
      ]
    }
  ]
}